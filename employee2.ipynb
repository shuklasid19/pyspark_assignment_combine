{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fff71a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b38073",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark  = SparkSession.builder.master('local[3]').appName('assignment3').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ade53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee1 = spark.read.option('inferSchema' , 'True').\\\n",
    "    option('header', 'True').csv('data\\Employee_info_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5451f5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Id: int, Employee_id: int, City: string, State: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "293fc323",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee2 = spark.read.option('inferSchema' , 'True').\\\n",
    "    option('header', 'True').csv('data\\Employee_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6240786c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----------------+\n",
      "|  Id|    Name|      Department|\n",
      "+----+--------+----------------+\n",
      "| 100|    Aman|Data Engineering|\n",
      "| 200| Saurabh|Data Engineering|\n",
      "| 300|   Mohit|          DavOps|\n",
      "| 400|  Kashif|          DAvOps|\n",
      "| 500|   Eniya|          DAvOps|\n",
      "| 600|   Anand|          DAvOps|\n",
      "| 700|  Murali|Data Engineering|\n",
      "| 800|  Ramesh|            Null|\n",
      "| 900|  Suresh|            Null|\n",
      "|1000|Himanshu|            Null|\n",
      "+----+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a498a3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+--------+-----+\n",
      "|  Id|Employee_id|    City|State|\n",
      "+----+-----------+--------+-----+\n",
      "| 100|       2555|  Indore|   MP|\n",
      "| 200|       2456|  Indore|   MP|\n",
      "| 300|       3265|   Surat|   GJ|\n",
      "| 400|       7896|Banglore|   KA|\n",
      "| 500|       4562|Banglore|   KA|\n",
      "| 600|       8524|Banglore|   KA|\n",
      "| 700|       6666|Banglore|   KA|\n",
      "| 800|       9853|Banglore|   KA|\n",
      "| 900|       1594|    Null|   JK|\n",
      "|1000|       7894|    Null|   JK|\n",
      "+----+-----------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3244f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bc58220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a357c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = employee1.join(employee2, employee1.Id == employee2.Id, 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b01176e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+--------+-----+----+--------+----------------+\n",
      "|  Id|Employee_id|    City|State|  Id|    Name|      Department|\n",
      "+----+-----------+--------+-----+----+--------+----------------+\n",
      "| 100|       2555|  Indore|   MP| 100|    Aman|Data Engineering|\n",
      "| 200|       2456|  Indore|   MP| 200| Saurabh|Data Engineering|\n",
      "| 300|       3265|   Surat|   GJ| 300|   Mohit|          DavOps|\n",
      "| 400|       7896|Banglore|   KA| 400|  Kashif|          DAvOps|\n",
      "| 500|       4562|Banglore|   KA| 500|   Eniya|          DAvOps|\n",
      "| 600|       8524|Banglore|   KA| 600|   Anand|          DAvOps|\n",
      "| 700|       6666|Banglore|   KA| 700|  Murali|Data Engineering|\n",
      "| 800|       9853|Banglore|   KA| 800|  Ramesh|            Null|\n",
      "| 900|       1594|    Null|   JK| 900|  Suresh|            Null|\n",
      "|1000|       7894|    Null|   JK|1000|Himanshu|            Null|\n",
      "+----+-----------+--------+-----+----+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a6ae707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7ccbf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+--------+-----+----+--------+----------------+\n",
      "|  Id|Employee_id|    City|State|  Id|    Name|      Department|\n",
      "+----+-----------+--------+-----+----+--------+----------------+\n",
      "| 100|       2555|  Indore|   MP| 100|    Aman|Data Engineering|\n",
      "| 200|       2456|  Indore|   MP| 200| Saurabh|Data Engineering|\n",
      "| 300|       3265|   Surat|   GJ| 300|   Mohit|          DavOps|\n",
      "| 400|       7896|Banglore|   KA| 400|  Kashif|          DAvOps|\n",
      "| 500|       4562|Banglore|   KA| 500|   Eniya|          DAvOps|\n",
      "| 600|       8524|Banglore|   KA| 600|   Anand|          DAvOps|\n",
      "| 700|       6666|Banglore|   KA| 700|  Murali|Data Engineering|\n",
      "| 800|       9853|Banglore|   KA| 800|  Ramesh|            Null|\n",
      "| 900|       1594|    Null|   JK| 900|  Suresh|            Null|\n",
      "|1000|       7894|    Null|   JK|1000|Himanshu|            Null|\n",
      "+----+-----------+--------+-----+----+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.na.fill(\"Banglore\",[\"City\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5115260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Employee_id: integer (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e2db4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+--------+-----+----+--------+----------------+\n",
      "|  Id|Employee_id|    City|State|  Id|    Name|      Department|\n",
      "+----+-----------+--------+-----+----+--------+----------------+\n",
      "| 100|       2555|  Indore|   MP| 100|    Aman|Data Engineering|\n",
      "| 200|       2456|  Indore|   MP| 200| Saurabh|Data Engineering|\n",
      "| 300|       3265|   Surat|   GJ| 300|   Mohit|          DavOps|\n",
      "| 400|       7896|Banglore|   KA| 400|  Kashif|          DAvOps|\n",
      "| 500|       4562|Banglore|   KA| 500|   Eniya|          DAvOps|\n",
      "| 600|       8524|Banglore|   KA| 600|   Anand|          DAvOps|\n",
      "| 700|       6666|Banglore|   KA| 700|  Murali|Data Engineering|\n",
      "| 800|       9853|Banglore|   KA| 800|  Ramesh|            Null|\n",
      "| 900|       1594|    Null|   JK| 900|  Suresh|            Null|\n",
      "|1000|       7894|    Null|   JK|1000|Himanshu|            Null|\n",
      "+----+-----------+--------+-----+----+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d074e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame = spark.read.option('header', 'True').csv('data\\Employee_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17fa9e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Id: string, Name: string, Department: string]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af35a53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----------------+\n",
      "|  Id|    Name|      Department|\n",
      "+----+--------+----------------+\n",
      "| 100|    Aman|Data Engineering|\n",
      "| 200| Saurabh|Data Engineering|\n",
      "| 300|   Mohit|          DavOps|\n",
      "| 400|  Kashif|          DAvOps|\n",
      "| 500|   Eniya|          DAvOps|\n",
      "| 600|   Anand|          DAvOps|\n",
      "| 700|  Murali|Data Engineering|\n",
      "| 800|  Ramesh|            Null|\n",
      "| 900|  Suresh|            Null|\n",
      "|1000|Himanshu|            Null|\n",
      "+----+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_frame.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c4bfe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_frame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "993f31d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id', 'Name', 'Department']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "400144f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----------------+\n",
      "|  Id|    Name|      Department|\n",
      "+----+--------+----------------+\n",
      "| 100|    Aman|Data Engineering|\n",
      "| 200| Saurabh|Data Engineering|\n",
      "| 300|   Mohit|          DavOps|\n",
      "| 400|  Kashif|          DAvOps|\n",
      "| 500|   Eniya|          DAvOps|\n",
      "| 600|   Anand|          DAvOps|\n",
      "| 700|  Murali|Data Engineering|\n",
      "| 800|  Ramesh|            Null|\n",
      "| 900|  Suresh|            Null|\n",
      "|1000|Himanshu|            Null|\n",
      "+----+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_frame.na.fill({'Department': 'DavOps'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4522f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "combined_df = combined_df.withColumn('Department', regexp_replace('Department', 'Null', 'DavOps'))\\\n",
    ".withColumn('City', regexp_replace('City', 'Null', 'Banglore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70fb8b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+--------+-----+----+--------+----------------+\n",
      "|  Id|Employee_id|    City|State|  Id|    Name|      Department|\n",
      "+----+-----------+--------+-----+----+--------+----------------+\n",
      "| 100|       2555|  Indore|   MP| 100|    Aman|Data Engineering|\n",
      "| 200|       2456|  Indore|   MP| 200| Saurabh|Data Engineering|\n",
      "| 300|       3265|   Surat|   GJ| 300|   Mohit|          DavOps|\n",
      "| 400|       7896|Banglore|   KA| 400|  Kashif|          DAvOps|\n",
      "| 500|       4562|Banglore|   KA| 500|   Eniya|          DAvOps|\n",
      "| 600|       8524|Banglore|   KA| 600|   Anand|          DAvOps|\n",
      "| 700|       6666|Banglore|   KA| 700|  Murali|Data Engineering|\n",
      "| 800|       9853|Banglore|   KA| 800|  Ramesh|          DavOps|\n",
      "| 900|       1594|Banglore|   JK| 900|  Suresh|          DavOps|\n",
      "|1000|       7894|Banglore|   JK|1000|Himanshu|          DavOps|\n",
      "+----+-----------+--------+-----+----+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc84dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
